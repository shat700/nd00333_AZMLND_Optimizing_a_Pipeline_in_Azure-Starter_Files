# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
This dataset contains data about bank marketing. With the focus on data of the number of times a client was contacted for the campaign, the history of contact, job, loan and housing we seek to predict whether the client opted for a bank deposit or not.
The best performing model was a VotingEnsemble obtained through AutoML with the primary metric 'accuracy' value as 0.916570. 

## Scikit-learn Pipeline
In this scikit-learn pipeline a workspace and a curated environment were initialized followed by creating a compute cluster and configuring the training run by creating a HyperDriveConfig and AutoMLConfig for comparison. Finally the run was submitted and the best model was saved and registered. The dataset is tabular which is imported from a URL in the training script. The data is one hot encoded and split into train and test sets. Further the hyperparameters such as C variable (inverse regularization parameter) and maximum number of iterations are set. Accuracy is chosen as the primary metric and logistic regression is the algorithm applied to obtain the best run. Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable (y) is a binary variable.

**What are the benefits of the parameter sampler you chose?**
Random sampling supports discrete and continuous hyperparameters as well as early termination of low-performance runs. It is also helpful in improving results by doing initial search.

**What are the benefits of the early stopping policy you chose?**
Bandit policy is based on slack factor/slack amount and evaluation interval. Bandit terminates runs where the primary metric is not within the specified slack factor/slack amount compared to the best performing run.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**


## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
