Optimizing an ML Pipeline in Azure for prediction of Fixed Deposit

Overview

This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

Summary

This dataset contains data about bank marketing. With the focus on data of the number of times a client was contacted for the campaign, the history of contact, job, loan and housing we seek to predict whether the client opted for a bank deposit or not.
The best performing model was a VotingEnsemble obtained through AutoML with the primary metric accuracy as '0.916570'. 

Scikit-learn Pipeline

In this scikit-learn pipeline a workspace and a curated environment were initialized followed by creating a compute cluster and configuring the training run by creating a HyperDriveConfig and AutoMLConfig for comparison. Finally the run was submitted and the best model was saved and registered. The dataset is tabular which is imported from a URL in the training script. The data is one hot encoded and split into train and test sets. Further the hyperparameters such as C variable (inverse regularization parameter) and maximum number of iterations are set. Accuracy is chosen as the primary metric and logistic regression is the algorithm applied to obtain the best run. Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable (y) is a binary variable.

For parameter sampling, random sampler was used which supports discrete and continuous hyperparameters as well as early termination of low-performance runs. It is also helpful in improving results by doing initial search.

Bandit policy was chosen as the early termination policy. It is based on slack factor/slack amount and evaluation interval. Bandit terminates runs where the primary metric is not within the specified slack factor/slack amount compared to the best performing run.

AutoML

Overall, 23 iterations were performed in 30 minutes duration to obtain the best model. VotingEnsemble is the model generated by AutoML as the best one with the highest accuracy of '0.916570'. The duration it took for this model to run was 1 minute and 26 seconds.
The output showcases a detailed account of all the metrics for the best model. For example, AUC is the proportion of correctly classified samples. The closer the value is to 1, the more is the true positive rate, the better will be the performance of the model. Log_loss of '0.21363' is good since it tells about the negative-log likelihood of a logistic model. A matthews_correlation coefficient of '0.54869' signifies near to perfect prediction capabilities of the model. The arithmetic mean of precision for each class is '0.799512' whereas precision_score_micro and precision_score_weighted are closer to 1. The closer precision is to 1, the ability of a model to avoid labeling negative samples as positive is higher. Similarly for recall, the ability of a model to detect all positive samples is not that good for each class than when computed globally and/or weighted.

Pipeline comparison

The best model generated by hyperdrive run had the accuracy of '0.910369'. Whereas, the best model generated by AutoML run had the accuracy of '0.916570'. Therefore, the best overall model was concluded to be the VotingEnsemble generated by AutoML. The main difference between the architecture of hyperdrive run and AutoML run was found to be the specification of parameter sampler with two main parameters namely 'C variable' and 'max_iter' with their respective distribution over the hyperparameter space. Another difference was the inclusion of an early termination policy in case of hyperdrive run to automatically terminate poorly performing runs thereby improving computational efficiency. The bandit policy as the earlt termination policy consists of parameters such as 'evaluation_interval' of 1 which will apply the policy every time the training script reports the primary metric and 'delay_evaluation' which delays the first policy evaluation for a specified number of intervals '5'. This means a run is terminated at interval 5 if its best primary metric 'accuracy' is worse than the median of the running averages over intervals 1:5 across all training runs.

The reason behind the absence of sampling class and policy is that in case of AutoML, these hyperparameters are auto-specified to get the optimum results. Also, an exit criteria in the form of 'experiment_timeout_minutes=30' has been mentioned in AutoMLConfig object as a parameter. This also makes AutoML more time efficient and in this case a better option for obtaining the best model. 

Future work

The hyperdrive run took much longer to get the best run because of large number of specified iterations. A viable solution could be the use of a better vm_size and vm_priority as medium and not low if not high. This should help in saving more time if the expense is not significant. 

